# 中医舌诊系统研究流程 📋

## 1. 数据准备与预处理 🗃️

### 1.1 数据集收集 📸

中医舌诊系统需要大量的舌像图片及其对应的标注数据：

```
tongue_images/   # 原始舌像图片目录
tongue_labels/   # 对应的标注图片目录
```

标注数据应包含：
- 舌体区域的分割标注（二值图像）
- 舌体区域对应五脏的划分标注
- 中医专家的诊断结果（可选）

### 1.2 数据集划分 🔀

使用 `label/divide_datasets.py` 脚本将数据按 9:1 的比例划分为训练集和测试集：

```bash
python label/divide_datasets.py
```

执行后将生成以下目录结构：
```
tongue_data/
├── train_img/      # 训练集图像
├── train_label/    # 训练集标签
├── test_img/       # 测试集图像
└── test_label/     # 测试集标签
```

### 1.3 图像预处理 🔧

舌像图片预处理步骤包括：

1. **图像缩放**：将图像调整到适当大小，平衡计算效率和细节保留
   ```python
   def save_img(file_path, store_path):
       img = cv2.imread(file_path)
       img_shape = img.shape
       rate = max(img.shape[0]//1000, img.shape[1]//500)
       if rate > 1:
           img = cv2.resize(img, (img.shape[1]//rate, img.shape[0]//rate))
           cv2.imwrite(store_path, img)
           return rate, img_shape
       else:
           cv2.imwrite(store_path, img)
           return 1, img_shape
   ```

2. **数据增强**：在训练阶段可以使用以下增强方法增加数据多样性
   ```python
   def data_augmentation(image, mask):
       # 随机翻转
       if tf.random.uniform(()) > 0.5:
           image = tf.image.flip_left_right(image)
           mask = tf.image.flip_left_right(mask)
       
       # 随机亮度调整
       image = tf.image.random_brightness(image, 0.2)
       
       # 随机对比度调整
       image = tf.image.random_contrast(image, 0.8, 1.2)
       
       return image, mask
   ```

3. **标准化**：将图像像素值归一化到特定范围，有助于模型训练
   ```python
   # 归一化到[0,1]范围
   image = image / 255.0
   ```

## 2. 模型设计 🧩

### 2.1 舌体分割模型架构 🏗️

系统采用基于 ResUNet 的深度学习模型进行舌体分割：

```
输入图像 → 编码器(ResNet) → 跳跃连接 → 解码器 → 分割掩膜
```

ResUNet 模型结合了 ResNet 的残差学习和 U-Net 的编解码器结构：

1. **编码器**：采用 ResNet 提取特征，包含多个残差块
2. **跳跃连接**：将编码阶段的特征图连接到对应的解码阶段
3. **解码器**：通过转置卷积逐步恢复空间维度
4. **输出层**：使用 Softmax 激活函数输出像素级分割结果

### 2.2 损失函数设计 📉

结合多种损失函数以提高分割性能：

```python
def dice_loss(y_true, y_pred):
    """计算Dice损失，适合处理类别不平衡问题"""
    smooth = 1.
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + smooth) / (
        tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def combined_loss(y_true, y_pred):
    """结合交叉熵损失和Dice损失"""
    ce_loss = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    return ce_loss + dice
```

### 2.3 评估指标 📊

选择以下指标评估模型性能：

- **IoU (Intersection over Union)**：衡量预测区域与真实区域的重叠度
- **Dice系数**：类似IoU，对小目标更敏感
- **精确率和召回率**：评估分割的准确性和完整性
- **F1-Score**：精确率和召回率的调和平均，综合评估模型性能

## 3. 模型训练 🧠

### 3.1 基本训练流程 ⚙️

使用 keras_segmentation 框架训练模型：

```bash
python -m keras_segmentation.train \
    --checkpoints_path="weights/resunet" \
    --train_images="tongue_data/train_img/" \
    --train_annotations="tongue_data/train_label/" \
    --val_images="tongue_data/test_img/" \
    --val_annotations="tongue_data/test_label/" \
    --n_classes=2 \
    --input_height=512 \
    --input_width=512 \
    --model_name="resunet" \
    --batch_size=8 \
    --epochs=50
```

参数说明：
- `--checkpoints_path`: 模型权重保存路径
- `--train_images`: 训练集图像路径
- `--train_annotations`: 训练集标注路径
- `--val_images`: 验证集图像路径
- `--val_annotations`: 验证集标注路径
- `--n_classes`: 分类数量（2表示二分类：舌体和背景）
- `--input_height/width`: 输入图像尺寸
- `--model_name`: 模型架构名称
- `--batch_size`: 批次大小
- `--epochs`: 训练轮数

### 3.2 自定义训练脚本 🛠️

创建自定义训练脚本 `train/train.py` 实现更多高级功能：

```python
# 示例代码片段
import tensorflow as tf
from keras_segmentation.models.resunet import resunet
import matplotlib.pyplot as plt

# 创建模型
model = resunet(n_classes=2, input_height=512, input_width=512)

# 编译模型，使用自定义损失函数
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss=combined_loss,
    metrics=['accuracy', tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])]
)

# 设置回调函数
callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        "weights/resunet/best_model.h5", 
        save_best_only=True, 
        monitor='val_loss'
    ),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss', 
        factor=0.2, 
        patience=5
    ),
    tf.keras.callbacks.EarlyStopping(
        monitor='val_loss', 
        patience=10, 
        restore_best_weights=True
    ),
    tf.keras.callbacks.TensorBoard(log_dir='logs/')
]

# 训练模型
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=50,
    callbacks=callbacks
)

# 绘制训练历史
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='训练损失')
plt.plot(history.history['val_loss'], label='验证损失')
plt.title('训练和验证损失')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='训练准确率')
plt.plot(history.history['val_accuracy'], label='验证准确率')
plt.title('训练和验证准确率')
plt.legend()

plt.savefig('train/training_history.png')
```

### 3.3 训练技巧 💡

1. **学习率调度**：使用学习率衰减策略，在训练后期减小学习率
2. **批次标准化**：在每个卷积层后添加批次标准化，加速训练并提高泛化能力
3. **权重初始化**：使用 He 初始化等适合深度网络的初始化方法
4. **梯度裁剪**：防止梯度爆炸问题
5. **交叉验证**：使用 k-fold 交叉验证提高模型鲁棒性

## 4. 舌部质量检测 👅

### 4.1 舌体检测流程 🔍

舌部质量检测使用训练好的模型实现：

```python
def find_tongue(file_path):
    # 调整图像尺寸
    rate, img_shape = save_img(file_path, store_path)
    
    # 使用模型预测舌体区域
    with graph.as_default():
        pr, img = predict(model=model, inp=store_path)
    
    # 获取最大连通域（舌体区域）
    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    maxSize = 0
    for i in range(len(contours)):
        if cv2.contourArea(contours[maxSize]) < cv2.contourArea(contours[i]):
            maxSize = i
            
    mask = img.copy()
    mask[:, :] = 0
    cv2.drawContours(mask, contours, maxSize, (255,255, 255), -1)
    
    # 返回检测结果
    return {
        "code": 1,  # 检测成功
        "box": [x1, y1, x2, y2],  # 舌体边界框
        "msg": "检测成功"
    }, mask
```

### 4.2 舌体质量评估标准 🔎

系统会对以下方面进行评估以确保舌像质量：

1. **亮度检查**：确保图像亮度适中，不过暗或过亮
2. **对比度检查**：确保舌体与背景有足够对比度
3. **舌体姿态检查**：确保舌头正确伸出，姿态合适
4. **舌体完整性检查**：确保舌体完整可见
5. **焦点检查**：确保图像清晰，无明显模糊

### 4.3 舌体区域划分 🧩

将舌体划分为对应五脏的区域：

```python
def viscera_split(mask):
    # 获取舌头的最小正外接矩形
    min_x, max_x, min_y, max_y = get_tongue(mask)
    tongue_h = max_y - min_y
    
    # 肾线（舌尖部分对应肾）
    kidney_line_y = int(tongue_h*0.4) + min_y
    
    # 肺线（舌根部分对应肺）
    lung_line_y = int(tongue_h*0.8) + min_y
    
    # 脾线（舌中部对应脾）
    spleen_line_y = int((lung_line_y - kidney_line_y)/2 + kidney_line_y)
    
    # 绘制分割线
    # ...
    
    # 寻找连通区域
    labeled_img, num = measure.label(mask, background=0, return_num=True, connectivity=2)
    
    # 返回各个区域的像素坐标
    return kidney_mask, lung_mask, spleen_mask, liver_left_mask, liver_right_mask
```

## 5. 健康评估与诊断 💊

### 5.1 特征提取 🔬

从分割得到的舌体区域提取特征：

1. **颜色特征**：分析舌体颜色，提取色相、饱和度、明度特征
2. **纹理特征**：使用灰度共生矩阵(GLCM)等方法提取纹理特征
3. **形态特征**：分析舌体形状、边缘特征
4. **苔质特征**：分析舌苔厚度、分布情况

### 5.2 健康评分计算 📊

基于提取的特征计算健康评分：

```python
def Main(user_data, region_rate, user_history_healthy=None):
    # 加载经验权重
    ls = pd.read_csv(root_path + '/LS.csv', encoding='utf-8', header=None)
    ls = np.array(ls.loc[0, 180:])
    
    # 特征融合
    user_region_score = []
    for j in range(0, user_data.shape[0], 36):
        region = user_data[j:j + 36]
        region_ls = ls[j:j + 36]
        tmp = merge_feature(region, region_ls)
        user_region_score.append(tmp)
    
    # 归一化处理
    scaler_user_tongue_score = scaler_feature(user_region_score)
    
    # 计算各区域健康值
    merge_heart_score = scaler_user_tongue_score[1]  # 心
    merge_spleen_score = scaler_user_tongue_score[2]  # 脾
    merge_kidney_score = scaler_user_tongue_score[0]  # 肾
    merge_lung_score = scaler_user_tongue_score[1]  # 肺
    merge_liver_score = (scaler_user_tongue_score[3] + scaler_user_tongue_score[4]) / 2  # 肝
    
    # 映射到[-1, 1]范围
    if user_history_healthy is not None and len(user_history_healthy.shape) > 1:
        # 使用历史数据进行个性化评分
        # ...
    else:
        # 预设用户各脏器的健康值为0，即预设用户是健康的
        # ...
        
    # 返回健康评分
    return [healthy_score, heart_score, spleen_score, kidney_score, lung_score, liver_score]
```

### 5.3 中医诊断建议 📝

基于健康评分给出中医诊断建议：

```python
def get_diagnosis(result):
    res = []
    if abs(result['res']['heart']) > 0.4:
        res.append('血虚')
    if abs(result['res']['spleen']) > 0.25:
        res.append('脾虚')
    if abs(result['res']['kidney']) > 0.4:
        res.append('肾虚')
    if abs(result['res']['lung']) > 0.4:
        res.append('气虚')
    if abs(result['res']['liver']) > 0.45:
        res.append('肝郁')
    if not res:
        res.append('健康')
    return res
```

## 6. 结果可视化与存储 💾

### 6.1 分割结果可视化 👁️

```python
def visualize_segmentation(image_path, mask):
    img_src = cv2.imread(image_path)
    img_merge = np.hstack([img_src, cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)])
    cv2.imshow('Segmentation Result', img_merge)
    cv2.waitKey()
    cv2.destroyAllWindows()
```

### 6.2 健康评分可视化 📈

创建雷达图显示五脏健康状况：

```python
def plot_health_radar(health_values):
    labels = ['心', '脾', '肾', '肺', '肝']
    values = [
        abs(health_values[1]),  # 心
        abs(health_values[2]),  # 脾
        abs(health_values[3]),  # 肾
        abs(health_values[4]),  # 肺
        abs(health_values[5])   # 肝
    ]
    
    angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False).tolist()
    values += values[:1]
    angles += angles[:1]
    labels += labels[:1]
    
    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
    ax.plot(angles, values, 'o-', linewidth=2)
    ax.fill(angles, values, alpha=0.25)
    ax.set_thetagrids(np.degrees(angles[:-1]), labels[:-1])
    ax.set_ylim(0, 1)
    ax.grid(True)
    
    plt.title('五脏健康状况')
    plt.savefig('example/health_radar.png')
```

### 6.3 结果保存 💾

将分析结果保存到Excel文件：

```python
def write_to_excel(user_id, health_values, diagnosis):
    if os.path.exists(excel_path):
        df = pd.read_excel(excel_path)
    else:
        df = pd.DataFrame(columns=['用户ID', '检测时间', '整体健康值', '心', '脾', '肾', '肺', '肝', '诊断结果'])
    
    new_data = {
        '用户ID': user_id,
        '检测时间': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        '整体健康值': health_values[0],
        '心': health_values[1],
        '脾': health_values[2],
        '肾': health_values[3],
        '肺': health_values[4],
        '肝': health_values[5],
        '诊断结果': '、'.join(diagnosis) if diagnosis else '健康'
    }
    
    df = pd.concat([df, pd.DataFrame([new_data])], ignore_index=True)
    df.to_excel(excel_path, index=False)
```

## 7. 系统评估与验证 ✅

### 7.1 模型性能评估 📊

评估舌体分割模型的性能：

```python
def evaluate_model():
    # 加载测试数据
    test_images = glob.glob("tongue_data/test_img/*.jpg")
    test_labels = [img_path.replace("test_img", "test_label") for img_path in test_images]
    
    # 评估指标
    iou_scores = []
    dice_scores = []
    
    for img_path, label_path in zip(test_images, test_labels):
        # 预测
        pred_mask = predict(model, img_path)
        
        # 加载真实标签
        true_mask = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)
        true_mask = cv2.resize(true_mask, (pred_mask.shape[1], pred_mask.shape[0]))
        true_mask = (true_mask > 0).astype(np.uint8)
        
        # 计算IoU
        intersection = np.logical_and(true_mask, pred_mask).sum()
        union = np.logical_or(true_mask, pred_mask).sum()
        iou = intersection / union if union > 0 else 0
        iou_scores.append(iou)
        
        # 计算Dice系数
        dice = (2 * intersection) / (true_mask.sum() + pred_mask.sum()) if (true_mask.sum() + pred_mask.sum()) > 0 else 0
        dice_scores.append(dice)
    
    # 输出平均指标
    print(f"平均IoU: {np.mean(iou_scores):.4f}")
    print(f"平均Dice系数: {np.mean(dice_scores):.4f}")
```

### 7.2 临床有效性验证 🏥

将系统诊断结果与中医专家诊断结果进行对比：

1. **一致性分析**：计算Kappa系数等一致性指标
2. **错误分析**：分析系统诊断错误的案例，总结错误模式
3. **专家反馈**：收集中医专家对系统的反馈意见

### 7.3 用户体验评估 👤

收集用户对系统的使用体验反馈：

1. **易用性**：系统操作是否简单直观
2. **可解释性**：用户是否理解诊断结果
3. **实用性**：用户是否觉得诊断结果有帮助
4. **响应速度**：系统处理速度是否满意

## 8. 系统优化与性能提升 🚀

### 8.1 模型加载机制优化 ⚡

为提高系统启动速度和运行效率，我们对模型加载机制进行了优化：

#### 8.1.1 单例模式实现 🔄

通过全局变量和单例设计模式，确保模型只被加载一次：

```python
# 单例模式实现
MODEL = None  # 全局变量

def get_model():
    """获取模型实例，如果不存在则创建"""
    global MODEL
    if MODEL is not None:
        return MODEL
        
    # 加载模型和权重
    latest_h5_weights = get_latest_h5_weights()
    if latest_h5_weights and os.path.exists(latest_h5_weights):
        print(f"正在加载最新h5格式权重: {latest_h5_weights}")
        MODEL = resnet50_unet(n_classes=2, input_height=576, input_width=768)
        MODEL.load_weights(latest_h5_weights)
        print("✓ 成功加载h5格式权重")
    else:
        print("未找到h5格式权重文件")
        MODEL = None
        
    return MODEL
```

#### 8.1.2 高效权重文件查找 🔍

优化的权重文件查找算法，无需正则表达式，直接通过文件名解析查找最高轮次的权重：

```python
def get_latest_h5_weights():
    """查找具有最高轮次的h5权重文件"""
    # 直接获取目录中的所有h5文件
    h5_files = [f for f in os.listdir(weights_dir) if f.endswith('.h5') and f.startswith('resunet.')]
    
    if not h5_files:
        return None
    
    # 提取数字部分并排序
    max_epoch = -1
    max_file = None
    
    for file_name in h5_files:
        # 从文件名中提取数字 (resunet.X.h5 格式)
        parts = file_name.split('.')
        if len(parts) >= 3 and parts[0] == 'resunet':
            try:
                epoch = int(parts[1])
                if epoch > max_epoch:
                    max_epoch = epoch
                    max_file = os.path.join(weights_dir, file_name)
            except ValueError:
                continue
    
    return max_file
```

#### 8.1.3 模块间共享模型实例 🔗

通过导入机制，确保不同模块使用相同的模型实例：

```python
# 在segmentation_tongue.py中
from ChineseMedicine_analysis import get_model
model = get_model()
```

#### 8.1.4 性能对比 📊

| 优化前 | 优化后 |
|-------|-------|
| 重复加载模型 | 单次加载 |
| 使用glob和正则表达式查找 | 使用直接字符串处理 |
| 多个模块各自加载 | 模块间共享模型实例 |
| 模块导入时即加载 | 按需加载机制 |
| 同时处理多种权重格式 | 专注于h5格式，提高兼容性 |

优化后的系统在启动和运行过程中显著减少了延迟时间，提高了用户体验和资源利用效率。

### 8.2 其他系统优化 💯

#### 8.2.1 文件操作优化

- 使用更高效的文件处理方式
- 避免频繁的文件读写操作
- 优化文件存储结构，便于快速访问

#### 8.2.2 内存管理优化

- 减少大型对象的重复创建
- 使用合适的数据结构和算法
- 及时释放不需要的内存资源

## 9. 未来工作 🔮

1. **多模态融合**：结合舌诊、脉诊等多种中医诊断方法
2. **移动端部署**：开发移动应用，方便用户自主检测
3. **多语言支持**：支持中英等多种语言界面
4. **个性化推荐**：基于诊断结果推荐个性化的保健建议
5. **数据挖掘**：对大量用户数据进行挖掘，发现疾病模式
6. **云端存储与分析**：提供云端存储和分析功能，实现远程诊断
7. **实时反馈系统**：提供即时健康建议和预警
8. **综合健康管理**：整合其他健康数据，提供全面健康管理