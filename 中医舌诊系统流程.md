# ä¸­åŒ»èˆŒè¯Šç³»ç»Ÿç ”ç©¶æµç¨‹ ğŸ“‹

## 1. æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç† ğŸ—ƒï¸

### 1.1 æ•°æ®é›†æ”¶é›† ğŸ“¸

ä¸­åŒ»èˆŒè¯Šç³»ç»Ÿéœ€è¦å¤§é‡çš„èˆŒåƒå›¾ç‰‡åŠå…¶å¯¹åº”çš„æ ‡æ³¨æ•°æ®ï¼š

```
tongue_images/   # åŸå§‹èˆŒåƒå›¾ç‰‡ç›®å½•
tongue_labels/   # å¯¹åº”çš„æ ‡æ³¨å›¾ç‰‡ç›®å½•
```

æ ‡æ³¨æ•°æ®åº”åŒ…å«ï¼š
- èˆŒä½“åŒºåŸŸçš„åˆ†å‰²æ ‡æ³¨ï¼ˆäºŒå€¼å›¾åƒï¼‰
- èˆŒä½“åŒºåŸŸå¯¹åº”äº”è„çš„åˆ’åˆ†æ ‡æ³¨
- ä¸­åŒ»ä¸“å®¶çš„è¯Šæ–­ç»“æœï¼ˆå¯é€‰ï¼‰

### 1.2 æ•°æ®é›†åˆ’åˆ† ğŸ”€

ä½¿ç”¨ `label/divide_datasets.py` è„šæœ¬å°†æ•°æ®æŒ‰ 9:1 çš„æ¯”ä¾‹åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š

```bash
python label/divide_datasets.py
```

æ‰§è¡Œåå°†ç”Ÿæˆä»¥ä¸‹ç›®å½•ç»“æ„ï¼š
```
tongue_data/
â”œâ”€â”€ train_img/      # è®­ç»ƒé›†å›¾åƒ
â”œâ”€â”€ train_label/    # è®­ç»ƒé›†æ ‡ç­¾
â”œâ”€â”€ test_img/       # æµ‹è¯•é›†å›¾åƒ
â””â”€â”€ test_label/     # æµ‹è¯•é›†æ ‡ç­¾
```

### 1.3 å›¾åƒé¢„å¤„ç† ğŸ”§

èˆŒåƒå›¾ç‰‡é¢„å¤„ç†æ­¥éª¤åŒ…æ‹¬ï¼š

1. **å›¾åƒç¼©æ”¾**ï¼šå°†å›¾åƒè°ƒæ•´åˆ°é€‚å½“å¤§å°ï¼Œå¹³è¡¡è®¡ç®—æ•ˆç‡å’Œç»†èŠ‚ä¿ç•™
   ```python
   def save_img(file_path, store_path):
       img = cv2.imread(file_path)
       img_shape = img.shape
       rate = max(img.shape[0]//1000, img.shape[1]//500)
       if rate > 1:
           img = cv2.resize(img, (img.shape[1]//rate, img.shape[0]//rate))
           cv2.imwrite(store_path, img)
           return rate, img_shape
       else:
           cv2.imwrite(store_path, img)
           return 1, img_shape
   ```

2. **æ•°æ®å¢å¼º**ï¼šåœ¨è®­ç»ƒé˜¶æ®µå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å¢å¼ºæ–¹æ³•å¢åŠ æ•°æ®å¤šæ ·æ€§
   ```python
   def data_augmentation(image, mask):
       # éšæœºç¿»è½¬
       if tf.random.uniform(()) > 0.5:
           image = tf.image.flip_left_right(image)
           mask = tf.image.flip_left_right(mask)
       
       # éšæœºäº®åº¦è°ƒæ•´
       image = tf.image.random_brightness(image, 0.2)
       
       # éšæœºå¯¹æ¯”åº¦è°ƒæ•´
       image = tf.image.random_contrast(image, 0.8, 1.2)
       
       return image, mask
   ```

3. **æ ‡å‡†åŒ–**ï¼šå°†å›¾åƒåƒç´ å€¼å½’ä¸€åŒ–åˆ°ç‰¹å®šèŒƒå›´ï¼Œæœ‰åŠ©äºæ¨¡å‹è®­ç»ƒ
   ```python
   # å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
   image = image / 255.0
   ```

## 2. æ¨¡å‹è®¾è®¡ ğŸ§©

### 2.1 èˆŒä½“åˆ†å‰²æ¨¡å‹æ¶æ„ ğŸ—ï¸

ç³»ç»Ÿé‡‡ç”¨åŸºäº ResUNet çš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡ŒèˆŒä½“åˆ†å‰²ï¼š

```
è¾“å…¥å›¾åƒ â†’ ç¼–ç å™¨(ResNet) â†’ è·³è·ƒè¿æ¥ â†’ è§£ç å™¨ â†’ åˆ†å‰²æ©è†œ
```

ResUNet æ¨¡å‹ç»“åˆäº† ResNet çš„æ®‹å·®å­¦ä¹ å’Œ U-Net çš„ç¼–è§£ç å™¨ç»“æ„ï¼š

1. **ç¼–ç å™¨**ï¼šé‡‡ç”¨ ResNet æå–ç‰¹å¾ï¼ŒåŒ…å«å¤šä¸ªæ®‹å·®å—
2. **è·³è·ƒè¿æ¥**ï¼šå°†ç¼–ç é˜¶æ®µçš„ç‰¹å¾å›¾è¿æ¥åˆ°å¯¹åº”çš„è§£ç é˜¶æ®µ
3. **è§£ç å™¨**ï¼šé€šè¿‡è½¬ç½®å·ç§¯é€æ­¥æ¢å¤ç©ºé—´ç»´åº¦
4. **è¾“å‡ºå±‚**ï¼šä½¿ç”¨ Softmax æ¿€æ´»å‡½æ•°è¾“å‡ºåƒç´ çº§åˆ†å‰²ç»“æœ

### 2.2 æŸå¤±å‡½æ•°è®¾è®¡ ğŸ“‰

ç»“åˆå¤šç§æŸå¤±å‡½æ•°ä»¥æé«˜åˆ†å‰²æ€§èƒ½ï¼š

```python
def dice_loss(y_true, y_pred):
    """è®¡ç®—DiceæŸå¤±ï¼Œé€‚åˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"""
    smooth = 1.
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + smooth) / (
        tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def combined_loss(y_true, y_pred):
    """ç»“åˆäº¤å‰ç†µæŸå¤±å’ŒDiceæŸå¤±"""
    ce_loss = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    return ce_loss + dice
```

### 2.3 è¯„ä¼°æŒ‡æ ‡ ğŸ“Š

é€‰æ‹©ä»¥ä¸‹æŒ‡æ ‡è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼š

- **IoU (Intersection over Union)**ï¼šè¡¡é‡é¢„æµ‹åŒºåŸŸä¸çœŸå®åŒºåŸŸçš„é‡å åº¦
- **Diceç³»æ•°**ï¼šç±»ä¼¼IoUï¼Œå¯¹å°ç›®æ ‡æ›´æ•æ„Ÿ
- **ç²¾ç¡®ç‡å’Œå¬å›ç‡**ï¼šè¯„ä¼°åˆ†å‰²çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
- **F1-Score**ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ï¼Œç»¼åˆè¯„ä¼°æ¨¡å‹æ€§èƒ½

## 3. æ¨¡å‹è®­ç»ƒ ğŸ§ 

### 3.1 åŸºæœ¬è®­ç»ƒæµç¨‹ âš™ï¸

ä½¿ç”¨ keras_segmentation æ¡†æ¶è®­ç»ƒæ¨¡å‹ï¼š

```bash
python -m keras_segmentation.train \
    --checkpoints_path="weights/resunet" \
    --train_images="tongue_data/train_img/" \
    --train_annotations="tongue_data/train_label/" \
    --val_images="tongue_data/test_img/" \
    --val_annotations="tongue_data/test_label/" \
    --n_classes=2 \
    --input_height=512 \
    --input_width=512 \
    --model_name="resunet" \
    --batch_size=8 \
    --epochs=50
```

å‚æ•°è¯´æ˜ï¼š
- `--checkpoints_path`: æ¨¡å‹æƒé‡ä¿å­˜è·¯å¾„
- `--train_images`: è®­ç»ƒé›†å›¾åƒè·¯å¾„
- `--train_annotations`: è®­ç»ƒé›†æ ‡æ³¨è·¯å¾„
- `--val_images`: éªŒè¯é›†å›¾åƒè·¯å¾„
- `--val_annotations`: éªŒè¯é›†æ ‡æ³¨è·¯å¾„
- `--n_classes`: åˆ†ç±»æ•°é‡ï¼ˆ2è¡¨ç¤ºäºŒåˆ†ç±»ï¼šèˆŒä½“å’ŒèƒŒæ™¯ï¼‰
- `--input_height/width`: è¾“å…¥å›¾åƒå°ºå¯¸
- `--model_name`: æ¨¡å‹æ¶æ„åç§°
- `--batch_size`: æ‰¹æ¬¡å¤§å°
- `--epochs`: è®­ç»ƒè½®æ•°

### 3.2 è‡ªå®šä¹‰è®­ç»ƒè„šæœ¬ ğŸ› ï¸

åˆ›å»ºè‡ªå®šä¹‰è®­ç»ƒè„šæœ¬ `train/train.py` å®ç°æ›´å¤šé«˜çº§åŠŸèƒ½ï¼š

```python
# ç¤ºä¾‹ä»£ç ç‰‡æ®µ
import tensorflow as tf
from keras_segmentation.models.resunet import resunet
import matplotlib.pyplot as plt

# åˆ›å»ºæ¨¡å‹
model = resunet(n_classes=2, input_height=512, input_width=512)

# ç¼–è¯‘æ¨¡å‹ï¼Œä½¿ç”¨è‡ªå®šä¹‰æŸå¤±å‡½æ•°
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss=combined_loss,
    metrics=['accuracy', tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])]
)

# è®¾ç½®å›è°ƒå‡½æ•°
callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        "weights/resunet/best_model.h5", 
        save_best_only=True, 
        monitor='val_loss'
    ),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss', 
        factor=0.2, 
        patience=5
    ),
    tf.keras.callbacks.EarlyStopping(
        monitor='val_loss', 
        patience=10, 
        restore_best_weights=True
    ),
    tf.keras.callbacks.TensorBoard(log_dir='logs/')
]

# è®­ç»ƒæ¨¡å‹
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=50,
    callbacks=callbacks
)

# ç»˜åˆ¶è®­ç»ƒå†å²
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')
plt.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')
plt.title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡')
plt.plot(history.history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡')
plt.title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡')
plt.legend()

plt.savefig('train/training_history.png')
```

### 3.3 è®­ç»ƒæŠ€å·§ ğŸ’¡

1. **å­¦ä¹ ç‡è°ƒåº¦**ï¼šä½¿ç”¨å­¦ä¹ ç‡è¡°å‡ç­–ç•¥ï¼Œåœ¨è®­ç»ƒåæœŸå‡å°å­¦ä¹ ç‡
2. **æ‰¹æ¬¡æ ‡å‡†åŒ–**ï¼šåœ¨æ¯ä¸ªå·ç§¯å±‚åæ·»åŠ æ‰¹æ¬¡æ ‡å‡†åŒ–ï¼ŒåŠ é€Ÿè®­ç»ƒå¹¶æé«˜æ³›åŒ–èƒ½åŠ›
3. **æƒé‡åˆå§‹åŒ–**ï¼šä½¿ç”¨ He åˆå§‹åŒ–ç­‰é€‚åˆæ·±åº¦ç½‘ç»œçš„åˆå§‹åŒ–æ–¹æ³•
4. **æ¢¯åº¦è£å‰ª**ï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸é—®é¢˜
5. **äº¤å‰éªŒè¯**ï¼šä½¿ç”¨ k-fold äº¤å‰éªŒè¯æé«˜æ¨¡å‹é²æ£’æ€§

## 4. èˆŒéƒ¨è´¨é‡æ£€æµ‹ ğŸ‘…

### 4.1 èˆŒä½“æ£€æµ‹æµç¨‹ ğŸ”

èˆŒéƒ¨è´¨é‡æ£€æµ‹ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å®ç°ï¼š

```python
def find_tongue(file_path):
    # è°ƒæ•´å›¾åƒå°ºå¯¸
    rate, img_shape = save_img(file_path, store_path)
    
    # ä½¿ç”¨æ¨¡å‹é¢„æµ‹èˆŒä½“åŒºåŸŸ
    with graph.as_default():
        pr, img = predict(model=model, inp=store_path)
    
    # è·å–æœ€å¤§è¿é€šåŸŸï¼ˆèˆŒä½“åŒºåŸŸï¼‰
    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    maxSize = 0
    for i in range(len(contours)):
        if cv2.contourArea(contours[maxSize]) < cv2.contourArea(contours[i]):
            maxSize = i
            
    mask = img.copy()
    mask[:, :] = 0
    cv2.drawContours(mask, contours, maxSize, (255,255, 255), -1)
    
    # è¿”å›æ£€æµ‹ç»“æœ
    return {
        "code": 1,  # æ£€æµ‹æˆåŠŸ
        "box": [x1, y1, x2, y2],  # èˆŒä½“è¾¹ç•Œæ¡†
        "msg": "æ£€æµ‹æˆåŠŸ"
    }, mask
```

### 4.2 èˆŒä½“è´¨é‡è¯„ä¼°æ ‡å‡† ğŸ”

ç³»ç»Ÿä¼šå¯¹ä»¥ä¸‹æ–¹é¢è¿›è¡Œè¯„ä¼°ä»¥ç¡®ä¿èˆŒåƒè´¨é‡ï¼š

1. **äº®åº¦æ£€æŸ¥**ï¼šç¡®ä¿å›¾åƒäº®åº¦é€‚ä¸­ï¼Œä¸è¿‡æš—æˆ–è¿‡äº®
2. **å¯¹æ¯”åº¦æ£€æŸ¥**ï¼šç¡®ä¿èˆŒä½“ä¸èƒŒæ™¯æœ‰è¶³å¤Ÿå¯¹æ¯”åº¦
3. **èˆŒä½“å§¿æ€æ£€æŸ¥**ï¼šç¡®ä¿èˆŒå¤´æ­£ç¡®ä¼¸å‡ºï¼Œå§¿æ€åˆé€‚
4. **èˆŒä½“å®Œæ•´æ€§æ£€æŸ¥**ï¼šç¡®ä¿èˆŒä½“å®Œæ•´å¯è§
5. **ç„¦ç‚¹æ£€æŸ¥**ï¼šç¡®ä¿å›¾åƒæ¸…æ™°ï¼Œæ— æ˜æ˜¾æ¨¡ç³Š

### 4.3 èˆŒä½“åŒºåŸŸåˆ’åˆ† ğŸ§©

å°†èˆŒä½“åˆ’åˆ†ä¸ºå¯¹åº”äº”è„çš„åŒºåŸŸï¼š

```python
def viscera_split(mask):
    # è·å–èˆŒå¤´çš„æœ€å°æ­£å¤–æ¥çŸ©å½¢
    min_x, max_x, min_y, max_y = get_tongue(mask)
    tongue_h = max_y - min_y
    
    # è‚¾çº¿ï¼ˆèˆŒå°–éƒ¨åˆ†å¯¹åº”è‚¾ï¼‰
    kidney_line_y = int(tongue_h*0.4) + min_y
    
    # è‚ºçº¿ï¼ˆèˆŒæ ¹éƒ¨åˆ†å¯¹åº”è‚ºï¼‰
    lung_line_y = int(tongue_h*0.8) + min_y
    
    # è„¾çº¿ï¼ˆèˆŒä¸­éƒ¨å¯¹åº”è„¾ï¼‰
    spleen_line_y = int((lung_line_y - kidney_line_y)/2 + kidney_line_y)
    
    # ç»˜åˆ¶åˆ†å‰²çº¿
    # ...
    
    # å¯»æ‰¾è¿é€šåŒºåŸŸ
    labeled_img, num = measure.label(mask, background=0, return_num=True, connectivity=2)
    
    # è¿”å›å„ä¸ªåŒºåŸŸçš„åƒç´ åæ ‡
    return kidney_mask, lung_mask, spleen_mask, liver_left_mask, liver_right_mask
```

## 5. å¥åº·è¯„ä¼°ä¸è¯Šæ–­ ğŸ’Š

### 5.1 ç‰¹å¾æå– ğŸ”¬

ä»åˆ†å‰²å¾—åˆ°çš„èˆŒä½“åŒºåŸŸæå–ç‰¹å¾ï¼š

1. **é¢œè‰²ç‰¹å¾**ï¼šåˆ†æèˆŒä½“é¢œè‰²ï¼Œæå–è‰²ç›¸ã€é¥±å’Œåº¦ã€æ˜åº¦ç‰¹å¾
2. **çº¹ç†ç‰¹å¾**ï¼šä½¿ç”¨ç°åº¦å…±ç”ŸçŸ©é˜µ(GLCM)ç­‰æ–¹æ³•æå–çº¹ç†ç‰¹å¾
3. **å½¢æ€ç‰¹å¾**ï¼šåˆ†æèˆŒä½“å½¢çŠ¶ã€è¾¹ç¼˜ç‰¹å¾
4. **è‹”è´¨ç‰¹å¾**ï¼šåˆ†æèˆŒè‹”åšåº¦ã€åˆ†å¸ƒæƒ…å†µ

### 5.2 å¥åº·è¯„åˆ†è®¡ç®— ğŸ“Š

åŸºäºæå–çš„ç‰¹å¾è®¡ç®—å¥åº·è¯„åˆ†ï¼š

```python
def Main(user_data, region_rate, user_history_healthy=None):
    # åŠ è½½ç»éªŒæƒé‡
    ls = pd.read_csv(root_path + '/LS.csv', encoding='utf-8', header=None)
    ls = np.array(ls.loc[0, 180:])
    
    # ç‰¹å¾èåˆ
    user_region_score = []
    for j in range(0, user_data.shape[0], 36):
        region = user_data[j:j + 36]
        region_ls = ls[j:j + 36]
        tmp = merge_feature(region, region_ls)
        user_region_score.append(tmp)
    
    # å½’ä¸€åŒ–å¤„ç†
    scaler_user_tongue_score = scaler_feature(user_region_score)
    
    # è®¡ç®—å„åŒºåŸŸå¥åº·å€¼
    merge_heart_score = scaler_user_tongue_score[1]  # å¿ƒ
    merge_spleen_score = scaler_user_tongue_score[2]  # è„¾
    merge_kidney_score = scaler_user_tongue_score[0]  # è‚¾
    merge_lung_score = scaler_user_tongue_score[1]  # è‚º
    merge_liver_score = (scaler_user_tongue_score[3] + scaler_user_tongue_score[4]) / 2  # è‚
    
    # æ˜ å°„åˆ°[-1, 1]èŒƒå›´
    if user_history_healthy is not None and len(user_history_healthy.shape) > 1:
        # ä½¿ç”¨å†å²æ•°æ®è¿›è¡Œä¸ªæ€§åŒ–è¯„åˆ†
        # ...
    else:
        # é¢„è®¾ç”¨æˆ·å„è„å™¨çš„å¥åº·å€¼ä¸º0ï¼Œå³é¢„è®¾ç”¨æˆ·æ˜¯å¥åº·çš„
        # ...
        
    # è¿”å›å¥åº·è¯„åˆ†
    return [healthy_score, heart_score, spleen_score, kidney_score, lung_score, liver_score]
```

### 5.3 ä¸­åŒ»è¯Šæ–­å»ºè®® ğŸ“

åŸºäºå¥åº·è¯„åˆ†ç»™å‡ºä¸­åŒ»è¯Šæ–­å»ºè®®ï¼š

```python
def get_diagnosis(result):
    res = []
    if abs(result['res']['heart']) > 0.4:
        res.append('è¡€è™š')
    if abs(result['res']['spleen']) > 0.25:
        res.append('è„¾è™š')
    if abs(result['res']['kidney']) > 0.4:
        res.append('è‚¾è™š')
    if abs(result['res']['lung']) > 0.4:
        res.append('æ°”è™š')
    if abs(result['res']['liver']) > 0.45:
        res.append('è‚éƒ')
    if not res:
        res.append('å¥åº·')
    return res
```

## 6. ç»“æœå¯è§†åŒ–ä¸å­˜å‚¨ ğŸ’¾

### 6.1 åˆ†å‰²ç»“æœå¯è§†åŒ– ğŸ‘ï¸

```python
def visualize_segmentation(image_path, mask):
    img_src = cv2.imread(image_path)
    img_merge = np.hstack([img_src, cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)])
    cv2.imshow('Segmentation Result', img_merge)
    cv2.waitKey()
    cv2.destroyAllWindows()
```

### 6.2 å¥åº·è¯„åˆ†å¯è§†åŒ– ğŸ“ˆ

åˆ›å»ºé›·è¾¾å›¾æ˜¾ç¤ºäº”è„å¥åº·çŠ¶å†µï¼š

```python
def plot_health_radar(health_values):
    labels = ['å¿ƒ', 'è„¾', 'è‚¾', 'è‚º', 'è‚']
    values = [
        abs(health_values[1]),  # å¿ƒ
        abs(health_values[2]),  # è„¾
        abs(health_values[3]),  # è‚¾
        abs(health_values[4]),  # è‚º
        abs(health_values[5])   # è‚
    ]
    
    angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False).tolist()
    values += values[:1]
    angles += angles[:1]
    labels += labels[:1]
    
    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
    ax.plot(angles, values, 'o-', linewidth=2)
    ax.fill(angles, values, alpha=0.25)
    ax.set_thetagrids(np.degrees(angles[:-1]), labels[:-1])
    ax.set_ylim(0, 1)
    ax.grid(True)
    
    plt.title('äº”è„å¥åº·çŠ¶å†µ')
    plt.savefig('example/health_radar.png')
```

### 6.3 ç»“æœä¿å­˜ ğŸ’¾

å°†åˆ†æç»“æœä¿å­˜åˆ°Excelæ–‡ä»¶ï¼š

```python
def write_to_excel(user_id, health_values, diagnosis):
    if os.path.exists(excel_path):
        df = pd.read_excel(excel_path)
    else:
        df = pd.DataFrame(columns=['ç”¨æˆ·ID', 'æ£€æµ‹æ—¶é—´', 'æ•´ä½“å¥åº·å€¼', 'å¿ƒ', 'è„¾', 'è‚¾', 'è‚º', 'è‚', 'è¯Šæ–­ç»“æœ'])
    
    new_data = {
        'ç”¨æˆ·ID': user_id,
        'æ£€æµ‹æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'æ•´ä½“å¥åº·å€¼': health_values[0],
        'å¿ƒ': health_values[1],
        'è„¾': health_values[2],
        'è‚¾': health_values[3],
        'è‚º': health_values[4],
        'è‚': health_values[5],
        'è¯Šæ–­ç»“æœ': 'ã€'.join(diagnosis) if diagnosis else 'å¥åº·'
    }
    
    df = pd.concat([df, pd.DataFrame([new_data])], ignore_index=True)
    df.to_excel(excel_path, index=False)
```

## 7. ç³»ç»Ÿè¯„ä¼°ä¸éªŒè¯ âœ…

### 7.1 æ¨¡å‹æ€§èƒ½è¯„ä¼° ğŸ“Š

è¯„ä¼°èˆŒä½“åˆ†å‰²æ¨¡å‹çš„æ€§èƒ½ï¼š

```python
def evaluate_model():
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_images = glob.glob("tongue_data/test_img/*.jpg")
    test_labels = [img_path.replace("test_img", "test_label") for img_path in test_images]
    
    # è¯„ä¼°æŒ‡æ ‡
    iou_scores = []
    dice_scores = []
    
    for img_path, label_path in zip(test_images, test_labels):
        # é¢„æµ‹
        pred_mask = predict(model, img_path)
        
        # åŠ è½½çœŸå®æ ‡ç­¾
        true_mask = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)
        true_mask = cv2.resize(true_mask, (pred_mask.shape[1], pred_mask.shape[0]))
        true_mask = (true_mask > 0).astype(np.uint8)
        
        # è®¡ç®—IoU
        intersection = np.logical_and(true_mask, pred_mask).sum()
        union = np.logical_or(true_mask, pred_mask).sum()
        iou = intersection / union if union > 0 else 0
        iou_scores.append(iou)
        
        # è®¡ç®—Diceç³»æ•°
        dice = (2 * intersection) / (true_mask.sum() + pred_mask.sum()) if (true_mask.sum() + pred_mask.sum()) > 0 else 0
        dice_scores.append(dice)
    
    # è¾“å‡ºå¹³å‡æŒ‡æ ‡
    print(f"å¹³å‡IoU: {np.mean(iou_scores):.4f}")
    print(f"å¹³å‡Diceç³»æ•°: {np.mean(dice_scores):.4f}")
```

### 7.2 ä¸´åºŠæœ‰æ•ˆæ€§éªŒè¯ ğŸ¥

å°†ç³»ç»Ÿè¯Šæ–­ç»“æœä¸ä¸­åŒ»ä¸“å®¶è¯Šæ–­ç»“æœè¿›è¡Œå¯¹æ¯”ï¼š

1. **ä¸€è‡´æ€§åˆ†æ**ï¼šè®¡ç®—Kappaç³»æ•°ç­‰ä¸€è‡´æ€§æŒ‡æ ‡
2. **é”™è¯¯åˆ†æ**ï¼šåˆ†æç³»ç»Ÿè¯Šæ–­é”™è¯¯çš„æ¡ˆä¾‹ï¼Œæ€»ç»“é”™è¯¯æ¨¡å¼
3. **ä¸“å®¶åé¦ˆ**ï¼šæ”¶é›†ä¸­åŒ»ä¸“å®¶å¯¹ç³»ç»Ÿçš„åé¦ˆæ„è§

### 7.3 ç”¨æˆ·ä½“éªŒè¯„ä¼° ğŸ‘¤

æ”¶é›†ç”¨æˆ·å¯¹ç³»ç»Ÿçš„ä½¿ç”¨ä½“éªŒåé¦ˆï¼š

1. **æ˜“ç”¨æ€§**ï¼šç³»ç»Ÿæ“ä½œæ˜¯å¦ç®€å•ç›´è§‚
2. **å¯è§£é‡Šæ€§**ï¼šç”¨æˆ·æ˜¯å¦ç†è§£è¯Šæ–­ç»“æœ
3. **å®ç”¨æ€§**ï¼šç”¨æˆ·æ˜¯å¦è§‰å¾—è¯Šæ–­ç»“æœæœ‰å¸®åŠ©
4. **å“åº”é€Ÿåº¦**ï¼šç³»ç»Ÿå¤„ç†é€Ÿåº¦æ˜¯å¦æ»¡æ„

## 8. ç³»ç»Ÿä¼˜åŒ–ä¸æ€§èƒ½æå‡ ğŸš€

### 8.1 æ¨¡å‹åŠ è½½æœºåˆ¶ä¼˜åŒ– âš¡

ä¸ºæé«˜ç³»ç»Ÿå¯åŠ¨é€Ÿåº¦å’Œè¿è¡Œæ•ˆç‡ï¼Œæˆ‘ä»¬å¯¹æ¨¡å‹åŠ è½½æœºåˆ¶è¿›è¡Œäº†ä¼˜åŒ–ï¼š

#### 8.1.1 å•ä¾‹æ¨¡å¼å®ç° ğŸ”„

é€šè¿‡å…¨å±€å˜é‡å’Œå•ä¾‹è®¾è®¡æ¨¡å¼ï¼Œç¡®ä¿æ¨¡å‹åªè¢«åŠ è½½ä¸€æ¬¡ï¼š

```python
# å•ä¾‹æ¨¡å¼å®ç°
MODEL = None  # å…¨å±€å˜é‡

def get_model():
    """è·å–æ¨¡å‹å®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    global MODEL
    if MODEL is not None:
        return MODEL
        
    # åŠ è½½æ¨¡å‹å’Œæƒé‡
    latest_h5_weights = get_latest_h5_weights()
    if latest_h5_weights and os.path.exists(latest_h5_weights):
        print(f"æ­£åœ¨åŠ è½½æœ€æ–°h5æ ¼å¼æƒé‡: {latest_h5_weights}")
        MODEL = resnet50_unet(n_classes=2, input_height=576, input_width=768)
        MODEL.load_weights(latest_h5_weights)
        print("âœ“ æˆåŠŸåŠ è½½h5æ ¼å¼æƒé‡")
    else:
        print("æœªæ‰¾åˆ°h5æ ¼å¼æƒé‡æ–‡ä»¶")
        MODEL = None
        
    return MODEL
```

#### 8.1.2 é«˜æ•ˆæƒé‡æ–‡ä»¶æŸ¥æ‰¾ ğŸ”

ä¼˜åŒ–çš„æƒé‡æ–‡ä»¶æŸ¥æ‰¾ç®—æ³•ï¼Œæ— éœ€æ­£åˆ™è¡¨è¾¾å¼ï¼Œç›´æ¥é€šè¿‡æ–‡ä»¶åè§£ææŸ¥æ‰¾æœ€é«˜è½®æ¬¡çš„æƒé‡ï¼š

```python
def get_latest_h5_weights():
    """æŸ¥æ‰¾å…·æœ‰æœ€é«˜è½®æ¬¡çš„h5æƒé‡æ–‡ä»¶"""
    # ç›´æ¥è·å–ç›®å½•ä¸­çš„æ‰€æœ‰h5æ–‡ä»¶
    h5_files = [f for f in os.listdir(weights_dir) if f.endswith('.h5') and f.startswith('resunet.')]
    
    if not h5_files:
        return None
    
    # æå–æ•°å­—éƒ¨åˆ†å¹¶æ’åº
    max_epoch = -1
    max_file = None
    
    for file_name in h5_files:
        # ä»æ–‡ä»¶åä¸­æå–æ•°å­— (resunet.X.h5 æ ¼å¼)
        parts = file_name.split('.')
        if len(parts) >= 3 and parts[0] == 'resunet':
            try:
                epoch = int(parts[1])
                if epoch > max_epoch:
                    max_epoch = epoch
                    max_file = os.path.join(weights_dir, file_name)
            except ValueError:
                continue
    
    return max_file
```

#### 8.1.3 æ¨¡å—é—´å…±äº«æ¨¡å‹å®ä¾‹ ğŸ”—

é€šè¿‡å¯¼å…¥æœºåˆ¶ï¼Œç¡®ä¿ä¸åŒæ¨¡å—ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹å®ä¾‹ï¼š

```python
# åœ¨segmentation_tongue.pyä¸­
from ChineseMedicine_analysis import get_model
model = get_model()
```

#### 8.1.4 æ€§èƒ½å¯¹æ¯” ğŸ“Š

| ä¼˜åŒ–å‰ | ä¼˜åŒ–å |
|-------|-------|
| é‡å¤åŠ è½½æ¨¡å‹ | å•æ¬¡åŠ è½½ |
| ä½¿ç”¨globå’Œæ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾ | ä½¿ç”¨ç›´æ¥å­—ç¬¦ä¸²å¤„ç† |
| å¤šä¸ªæ¨¡å—å„è‡ªåŠ è½½ | æ¨¡å—é—´å…±äº«æ¨¡å‹å®ä¾‹ |
| æ¨¡å—å¯¼å…¥æ—¶å³åŠ è½½ | æŒ‰éœ€åŠ è½½æœºåˆ¶ |
| åŒæ—¶å¤„ç†å¤šç§æƒé‡æ ¼å¼ | ä¸“æ³¨äºh5æ ¼å¼ï¼Œæé«˜å…¼å®¹æ€§ |

ä¼˜åŒ–åçš„ç³»ç»Ÿåœ¨å¯åŠ¨å’Œè¿è¡Œè¿‡ç¨‹ä¸­æ˜¾è‘—å‡å°‘äº†å»¶è¿Ÿæ—¶é—´ï¼Œæé«˜äº†ç”¨æˆ·ä½“éªŒå’Œèµ„æºåˆ©ç”¨æ•ˆç‡ã€‚

### 8.2 å…¶ä»–ç³»ç»Ÿä¼˜åŒ– ğŸ’¯

#### 8.2.1 æ–‡ä»¶æ“ä½œä¼˜åŒ–

- ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–‡ä»¶å¤„ç†æ–¹å¼
- é¿å…é¢‘ç¹çš„æ–‡ä»¶è¯»å†™æ“ä½œ
- ä¼˜åŒ–æ–‡ä»¶å­˜å‚¨ç»“æ„ï¼Œä¾¿äºå¿«é€Ÿè®¿é—®

#### 8.2.2 å†…å­˜ç®¡ç†ä¼˜åŒ–

- å‡å°‘å¤§å‹å¯¹è±¡çš„é‡å¤åˆ›å»º
- ä½¿ç”¨åˆé€‚çš„æ•°æ®ç»“æ„å’Œç®—æ³•
- åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å†…å­˜èµ„æº

## 9. æœªæ¥å·¥ä½œ ğŸ”®

1. **å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆèˆŒè¯Šã€è„‰è¯Šç­‰å¤šç§ä¸­åŒ»è¯Šæ–­æ–¹æ³•
2. **ç§»åŠ¨ç«¯éƒ¨ç½²**ï¼šå¼€å‘ç§»åŠ¨åº”ç”¨ï¼Œæ–¹ä¾¿ç”¨æˆ·è‡ªä¸»æ£€æµ‹
3. **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒä¸­è‹±ç­‰å¤šç§è¯­è¨€ç•Œé¢
4. **ä¸ªæ€§åŒ–æ¨è**ï¼šåŸºäºè¯Šæ–­ç»“æœæ¨èä¸ªæ€§åŒ–çš„ä¿å¥å»ºè®®
5. **æ•°æ®æŒ–æ˜**ï¼šå¯¹å¤§é‡ç”¨æˆ·æ•°æ®è¿›è¡ŒæŒ–æ˜ï¼Œå‘ç°ç–¾ç—…æ¨¡å¼
6. **äº‘ç«¯å­˜å‚¨ä¸åˆ†æ**ï¼šæä¾›äº‘ç«¯å­˜å‚¨å’Œåˆ†æåŠŸèƒ½ï¼Œå®ç°è¿œç¨‹è¯Šæ–­
7. **å®æ—¶åé¦ˆç³»ç»Ÿ**ï¼šæä¾›å³æ—¶å¥åº·å»ºè®®å’Œé¢„è­¦
8. **ç»¼åˆå¥åº·ç®¡ç†**ï¼šæ•´åˆå…¶ä»–å¥åº·æ•°æ®ï¼Œæä¾›å…¨é¢å¥åº·ç®¡ç†