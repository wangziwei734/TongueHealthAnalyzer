# ä¸­åŒ»èˆŒè¯Šç³»ç»Ÿä½¿ç”¨æŒ‡å— ğŸ“‹

## é¡¹ç›®ä»‹ç» ğŸ”

æœ¬ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºè®¡ç®—æœºè§†è§‰å’Œæœºå™¨å­¦ä¹ çš„ä¸­åŒ»èˆŒè¯Šåˆ†æç³»ç»Ÿï¼Œé€šè¿‡å¯¹èˆŒåƒå›¾ç‰‡è¿›è¡Œå¤„ç†ã€åˆ†å‰²å’Œç‰¹å¾æå–ï¼Œå¯ä»¥è‡ªåŠ¨è¯„ä¼°ç”¨æˆ·çš„æ•´ä½“å¥åº·çŠ¶å†µä»¥åŠå¿ƒã€è‚ã€è„¾ã€è‚ºã€è‚¾äº”è„çš„å¥åº·æƒ…å†µï¼Œå¹¶ç»™å‡ºç›¸åº”çš„ä¸­åŒ»è¯Šæ–­å»ºè®®ã€‚

### ç³»ç»Ÿç‰¹è‰² âœ¨

- **ä¼ ç»ŸåŒ»å­¦ä¸ç°ä»£æŠ€æœ¯çš„ç»“åˆ**ï¼šå°†ä¼ ç»Ÿä¸­åŒ»èˆŒè¯Šç†è®ºä¸ç°ä»£äººå·¥æ™ºèƒ½æŠ€æœ¯ç›¸ç»“åˆ
- **è‡ªåŠ¨åŒ–èˆŒä½“è¯†åˆ«ä¸åˆ†å‰²**ï¼šä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è‡ªåŠ¨æ£€æµ‹å¹¶åˆ†å‰²èˆŒä½“åŒºåŸŸ
- **å¤šåŒºåŸŸå¥åº·è¯„ä¼°**ï¼šå°†èˆŒä½“åˆ’åˆ†ä¸ºå¯¹åº”äº”è„çš„åŒºåŸŸï¼Œåˆ†åˆ«è¿›è¡Œåˆ†æ
- **ä¸ªæ€§åŒ–å¥åº·è®°å½•**ï¼šè®°å½•ç”¨æˆ·å†å²å¥åº·æ•°æ®ï¼Œå®ç°ä¸ªæ€§åŒ–åˆ†æ
- **å¯è§£é‡Šæ€§è¯Šæ–­ç»“æœ**ï¼šä¸ä»…æä¾›å¥åº·è¯„åˆ†ï¼Œè¿˜ç»™å‡ºå…·ä½“ä¸­åŒ»è¯Šæ–­å»ºè®®
- **ä¼˜åŒ–çš„æ¨¡å‹åŠ è½½æœºåˆ¶**ï¼šå•ä¾‹æ¨¡å¼æ¨¡å‹åŠ è½½å’Œæ™ºèƒ½æƒé‡æ–‡ä»¶æ£€æµ‹ï¼Œæé«˜ç³»ç»Ÿå“åº”é€Ÿåº¦

## ç¯å¢ƒå‡†å¤‡ ğŸ› ï¸

åœ¨è¿è¡Œç³»ç»Ÿå‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š

```bash
# å›¾åƒå¤„ç†ç›¸å…³
pip install opencv-python
pip install scikit-image

# æœºå™¨å­¦ä¹ ç›¸å…³
pip install tensorflow
pip install scikit-learn

# æ•°æ®å¤„ç†ç›¸å…³
pip install numpy
pip install pandas
pip install openpyxl

# å¯è§†åŒ–ç›¸å…³ï¼ˆå¯é€‰ï¼‰
pip install matplotlib
pip install seaborn
```

## ç³»ç»Ÿæ–‡ä»¶ç»“æ„ ğŸ“

```
ChineseMedicine/
â”œâ”€â”€ run.py                   # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ ChineseMedicine_analysis.py   # ä¸­åŒ»åˆ†æä¸»æ¨¡å—
â”œâ”€â”€ analysis/                # åˆ†ææ¨¡å—ç›®å½•
â”‚   â”œâ”€â”€ main.py              # å¥åº·å€¼è®¡ç®—ä¸»å‡½æ•°
â”‚   â”œâ”€â”€ merge_features.py    # ç‰¹å¾èåˆå‡½æ•°
â”‚   â””â”€â”€ LS.csv               # ç»éªŒæƒé‡æ•°æ®
â”œâ”€â”€ tongue/                  # èˆŒè¯Šæ¨¡å—ç›®å½•
â”‚   â”œâ”€â”€ haveTongue.py        # èˆŒä½“æ£€æµ‹æ¨¡å—
â”‚   â”œâ”€â”€ segmentation_tongue.py   # èˆŒé¢åˆ†å‰²æ¨¡å—
â”‚   â””â”€â”€ tongue_segmentation/ # èˆŒä½“åŒºåŸŸåˆ†å‰²æ¨¡å—
â”œâ”€â”€ keras_segmentation/      # å›¾åƒåˆ†å‰²æ¨¡å—
â”œâ”€â”€ weights/                 # æ¨¡å‹æƒé‡ç›®å½•
â”‚   â””â”€â”€ resunet.*.h5         # æ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆh5æ ¼å¼ï¼‰
â”œâ”€â”€ example/                 # ç¤ºä¾‹å›¾ç‰‡å’Œç»“æœç›®å½•
â”‚   â”œâ”€â”€ *.jpg                # æµ‹è¯•ç”¨çš„èˆŒåƒå›¾ç‰‡
â”‚   â””â”€â”€ expert_diagnosis.xlsx   # è¯Šæ–­ç»“æœè®°å½•è¡¨
â”œâ”€â”€ upload/                  # ä¸Šä¼ å›¾ç‰‡ä¸´æ—¶å­˜å‚¨ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”œâ”€â”€ features/                # ç‰¹å¾å­˜å‚¨ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”‚   â””â”€â”€ [ç”¨æˆ·ID]/            # æŒ‰ç”¨æˆ·IDåˆ†ç±»çš„ç‰¹å¾ç›®å½•
â”‚       â””â”€â”€ value.txt        # ç”¨æˆ·å†å²å¥åº·å€¼è®°å½•
â”œâ”€â”€ train/                   # æ¨¡å‹è®­ç»ƒç›¸å…³ï¼ˆè‡ªè¡Œåˆ›å»ºï¼‰
â”‚   â”œâ”€â”€ train.py             # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ plot_metrics.py      # æŒ‡æ ‡ç»˜å›¾è„šæœ¬
â”‚   â””â”€â”€ configs/             # è®­ç»ƒé…ç½®æ–‡ä»¶
â””â”€â”€ docs/                    # æ–‡æ¡£ç›®å½•ï¼ˆè‡ªè¡Œåˆ›å»ºï¼‰
    â”œâ”€â”€ model_structure.md   # æ¨¡å‹ç»“æ„æ–‡æ¡£
    â”œâ”€â”€ feature_extraction.md # ç‰¹å¾æå–æ–¹æ³•æ–‡æ¡£
    â””â”€â”€ evaluation.md        # è¯„ä¼°æ–¹æ³•æ–‡æ¡£
```

## æ¨¡å‹åŠ è½½æœºåˆ¶è¯´æ˜ ğŸ”„

ç³»ç»Ÿé‡‡ç”¨äº†ä¼˜åŒ–çš„æ¨¡å‹åŠ è½½æœºåˆ¶ï¼Œæé«˜è¿è¡Œæ•ˆç‡ï¼š

1. **å•ä¾‹æ¨¡å¼**ï¼šä½¿ç”¨å…¨å±€å˜é‡ç¡®ä¿æ¨¡å‹åªåŠ è½½ä¸€æ¬¡ï¼Œé¿å…é‡å¤åŠ è½½
2. **é«˜æ•ˆæƒé‡æŸ¥æ‰¾**ï¼šé‡‡ç”¨ç›´æ¥æ–‡ä»¶åè§£ææ–¹å¼ï¼Œå¿«é€Ÿå®šä½æœ€é«˜è½®æ¬¡çš„æƒé‡æ–‡ä»¶
3. **æ¨¡å—é—´å…±äº«**ï¼šä¸åŒæ¨¡å—é—´å…±äº«åŒä¸€ä¸ªæ¨¡å‹å®ä¾‹ï¼Œå‡å°‘å†…å­˜å ç”¨
4. **æ‡’åŠ è½½æœºåˆ¶**ï¼šåªåœ¨å®é™…éœ€è¦ä½¿ç”¨æ—¶æ‰åŠ è½½æ¨¡å‹ï¼Œä¼˜åŒ–èµ„æºåˆ©ç”¨
5. **h5æ ¼å¼æ”¯æŒ**ï¼šæ”¯æŒTensorFlowçš„h5æ ¼å¼æƒé‡æ–‡ä»¶ï¼Œç¡®ä¿ç‰ˆæœ¬å…¼å®¹æ€§

æ­¤æœºåˆ¶æ˜¾è‘—å‡å°‘äº†ç³»ç»Ÿå¯åŠ¨å’Œåˆ†æè¿‡ç¨‹ä¸­çš„å»¶è¿Ÿã€‚

## æ¨¡å‹æµ‹è¯•ä¸è¯„ä¼° ğŸ§ª

é™¤äº†ä¸»è¦çš„èˆŒè¯Šåˆ†æåŠŸèƒ½å¤–ï¼Œç³»ç»Ÿè¿˜æä¾›äº†æ¨¡å‹æµ‹è¯•ä¸è¯„ä¼°å·¥å…·ï¼š

### ä½¿ç”¨test.pyè¿›è¡Œæ¨¡å‹æµ‹è¯• ğŸ”¬

æ‚¨å¯ä»¥ä½¿ç”¨`test.py`è„šæœ¬å¯¹è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ€§èƒ½æµ‹è¯•ï¼š

```bash
python test.py
```

æ‰§è¡Œæ­¤å‘½ä»¤ä¼šï¼š

1. **åŠ è½½æœ€æ–°çš„æ¨¡å‹æƒé‡**: è‡ªåŠ¨æŸ¥æ‰¾å¹¶åŠ è½½`weights`ç›®å½•ä¸­è½®æ¬¡æœ€é«˜çš„h5æ ¼å¼æƒé‡æ–‡ä»¶
2. **é¢„æµ‹æµ‹è¯•é›†å›¾åƒ**: å¯¹`tongue_data/test_img/`ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒè¿›è¡Œåˆ†å‰²é¢„æµ‹
3. **ä¿å­˜é¢„æµ‹ç»“æœ**: å°†é¢„æµ‹ç»“æœä¿å­˜åˆ°`prediction/`ç›®å½•
4. **è¯„ä¼°æ¨¡å‹æ€§èƒ½**: å¦‚æœå­˜åœ¨`tongue_data/test_label/`ç›®å½•ï¼Œä¼šè®¡ç®—å¹¶è¾“å‡ºæ¨¡å‹çš„IoUæŒ‡æ ‡

é¢„æµ‹ç»“æœç¤ºä¾‹ï¼š
- åŸå§‹èˆŒåƒå›¾ç‰‡ï¼š`tongue_data/test_img/101_org.jpg`
- é¢„æµ‹åˆ†å‰²ç»“æœï¼š`prediction/101_org.jpg`

> ğŸ“ **æ³¨æ„**: é¦–æ¬¡è¿è¡Œæ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶åˆ›å»ºæ‰€éœ€çš„ç›®å½•ç»“æ„

### å‡†å¤‡æµ‹è¯•æ•°æ® ğŸ“Š

åœ¨ä½¿ç”¨æµ‹è¯•åŠŸèƒ½å‰ï¼Œè¯·ç¡®ä¿å‡†å¤‡å¥½æµ‹è¯•æ•°æ®ï¼š

1. åˆ›å»ºæµ‹è¯•å›¾åƒç›®å½•: `tongue_data/test_img/`
2. åˆ›å»ºæµ‹è¯•æ ‡ç­¾ç›®å½•: `tongue_data/test_label/` (ç”¨äºè¯„ä¼°ï¼Œå¯é€‰)
3. å°†æµ‹è¯•å›¾åƒå’Œå¯¹åº”æ ‡ç­¾æ”¾å…¥ç›¸åº”ç›®å½•

æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨æ•°æ®é›†åˆ’åˆ†å·¥å…·è‡ªåŠ¨ç”Ÿæˆè¿™äº›ç›®å½•:
```bash
python label/divide_datasets.py
```

### è§£è¯»æµ‹è¯•ç»“æœ ğŸ“ˆ

æµ‹è¯•å®Œæˆåï¼Œæ‚¨å¯ä»¥ï¼š

1. æ£€æŸ¥ `prediction/` ç›®å½•æŸ¥çœ‹åˆ†å‰²ç»“æœ
2. æŸ¥çœ‹è¾“å‡ºçš„IoUå€¼è¯„ä¼°æ¨¡å‹æ€§èƒ½ (æ•°å€¼è¶Šæ¥è¿‘1è¡¨ç¤ºåˆ†å‰²æ•ˆæœè¶Šå¥½)
3. æ¯”è¾ƒé¢„æµ‹ç»“æœä¸æ ‡ç­¾å›¾åƒï¼Œåˆ†ææ¨¡å‹çš„ä¼˜åŠ¿å’Œä¸è¶³

## ä½¿ç”¨æµç¨‹ ğŸ”„

### 1. è¿è¡ŒèˆŒä½“æ£€æµ‹ä¸åˆ†æ ğŸ‘…

ä½¿ç”¨ `run.py` æ–‡ä»¶è¿›è¡ŒèˆŒä½“æ£€æµ‹ã€åˆ†å‰²å’Œå¥åº·åˆ†æï¼š

```bash
python run.py
```

#### æ‰§è¡Œè¿‡ç¨‹è¯¦è§£ï¼š

1. **è¾“å…¥å›¾åƒ** ğŸ“¸
   - ç³»ç»Ÿé»˜è®¤ä½¿ç”¨ `example/0.jpg` ä½œä¸ºè¾“å…¥å›¾åƒ
   - å¦‚éœ€ä½¿ç”¨å…¶ä»–å›¾åƒï¼Œè¯·ä¿®æ”¹ `run.py` ä¸­çš„ `image_path` å˜é‡

2. **èˆŒä½“æ£€æµ‹** ğŸ”
   - è°ƒç”¨ `find_tongue()` å‡½æ•°æ£€æµ‹å›¾åƒä¸­çš„èˆŒä½“
   - ç³»ç»Ÿä¼šæ£€æŸ¥å›¾åƒè´¨é‡ï¼ˆäº®åº¦ã€å¯¹æ¯”åº¦ã€æ˜¯å¦å«æœ‰èˆŒä½“ç­‰ï¼‰
   - å¦‚æœæ£€æµ‹æˆåŠŸï¼Œä¼šè¿”å›èˆŒä½“åŒºåŸŸçš„åæ ‡å’Œæ©è†œå›¾åƒ

3. **åˆ†å‰²ç»“æœå±•ç¤º** ğŸ‘ï¸
   - ç³»ç»Ÿä¼šå¼¹å‡ºçª—å£æ˜¾ç¤ºåŸå›¾å’ŒèˆŒä½“åˆ†å‰²ç»“æœ
   - æŒ‰ä»»æ„é”®å…³é—­çª—å£ç»§ç»­æ‰§è¡Œ

4. **å¥åº·åˆ†æ** ğŸ“Š
   - è°ƒç”¨ `analysis()` å‡½æ•°è¿›è¡Œå¥åº·åˆ†æ
   - è®¡ç®—æ•´ä½“å¥åº·å€¼å’Œäº”è„ï¼ˆå¿ƒã€è‚ã€è„¾ã€è‚ºã€è‚¾ï¼‰å¥åº·å€¼
   - æ•°å€¼èŒƒå›´ä¸º[-1, 1]ï¼Œè¶Šæ¥è¿‘0è¡¨ç¤ºè¶Šå¥åº·

5. **è¯Šæ–­ç»“æœ** ğŸ“
   - æ ¹æ®å„è„è…‘å¥åº·å€¼ï¼Œç³»ç»Ÿä¼šç»™å‡ºç›¸åº”çš„ä¸­åŒ»è¯Šæ–­å»ºè®®
   - å¦‚"è¡€è™š"ã€"è„¾è™š"ã€"è‚¾è™š"ã€"æ°”è™š"ã€"è‚éƒ"ç­‰
   - å¦‚æœå„é¡¹æŒ‡æ ‡éƒ½æ­£å¸¸ï¼Œåˆ™è¯Šæ–­ä¸º"å¥åº·"

6. **ç»“æœä¿å­˜** ğŸ’¾
   - åˆ†æç»“æœä¼šè‡ªåŠ¨ä¿å­˜åˆ° `example/expert_diagnosis.xlsx` æ–‡ä»¶ä¸­
   - æ¯æ¬¡åˆ†æéƒ½ä¼šæ–°å¢ä¸€æ¡è®°å½•ï¼Œä¸ä¼šè¦†ç›–å†å²æ•°æ®

### 2. ç”Ÿæˆçš„æ–‡ä»¶åŠç›®å½•è¯´æ˜ ğŸ“‚

#### è‡ªåŠ¨åˆ›å»ºçš„ç›®å½•ï¼š

1. **upload/** æ–‡ä»¶å¤¹
   - ç”¨äºä¸´æ—¶å­˜å‚¨å¤„ç†ä¸­çš„å›¾åƒ
   - åˆ†æå®Œæˆåä¼šè‡ªåŠ¨æ¸…ç†

2. **features/[ç”¨æˆ·ID]/** æ–‡ä»¶å¤¹
   - å­˜å‚¨ç”¨æˆ·å¥åº·å€¼å†å²è®°å½•
   - æ¯ä¸ªç”¨æˆ·ä¸€ä¸ªç‹¬ç«‹ç›®å½•ï¼Œä»¥ç”¨æˆ·IDå‘½å
   - ç›®å½•ä¸‹çš„ `value.txt` æ–‡ä»¶è®°å½•ç”¨æˆ·å†æ¬¡æ£€æµ‹çš„å¥åº·å€¼

#### ç”Ÿæˆçš„æ–‡ä»¶ï¼š

1. **expert_diagnosis.xlsx**
   - ä½ç½®ï¼š`example/expert_diagnosis.xlsx`
   - å†…å®¹ï¼šæ‰€æœ‰ç”¨æˆ·çš„è¯Šæ–­è®°å½•
   - å­—æ®µåŒ…æ‹¬ï¼šç”¨æˆ·IDã€æ£€æµ‹æ—¶é—´ã€æ•´ä½“å¥åº·å€¼ã€å¿ƒã€è„¾ã€è‚¾ã€è‚ºã€è‚ã€è¯Šæ–­ç»“æœ

2. **value.txt**
   - ä½ç½®ï¼š`features/[ç”¨æˆ·ID]/value.txt`
   - å†…å®¹ï¼šç‰¹å®šç”¨æˆ·çš„å†å²å¥åº·å€¼è®°å½•
   - æ ¼å¼ï¼šæ¯è¡Œä¸ºä¸€æ¬¡æ£€æµ‹ç»“æœï¼Œä»¥é€—å·åˆ†éš”çš„å…­ä¸ªå€¼ï¼ˆæ•´ä½“ã€å¿ƒã€è„¾ã€è‚¾ã€è‚ºã€è‚ï¼‰

## è®­ç»ƒæ¨¡å‹ ğŸ§ 

æœ¬ç³»ç»Ÿä½¿ç”¨çš„èˆŒä½“åˆ†å‰²æ¨¡å‹åŸºäºResUNetæ¶æ„ï¼Œå¯ä»¥æ ¹æ®ä»¥ä¸‹æ­¥éª¤è®­ç»ƒè‡ªå·±çš„æ¨¡å‹ï¼š

### 1. æ•°æ®é›†å‡†å¤‡

é¦–å…ˆä½¿ç”¨æ•°æ®é›†åˆ’åˆ†å·¥å…·å‡†å¤‡è®­ç»ƒæ•°æ®ï¼š

```bash
python label/divide_datasets.py
```

è¿™ä¼šå°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ç¡®ä¿æ‚¨çš„æ•°æ®é›†ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
tongue_data/
â”œâ”€â”€ train_img/      # è®­ç»ƒé›†å›¾åƒ
â”œâ”€â”€ train_label/    # è®­ç»ƒé›†æ ‡ç­¾
â”œâ”€â”€ test_img/       # æµ‹è¯•é›†å›¾åƒ
â””â”€â”€ test_label/     # æµ‹è¯•é›†æ ‡ç­¾
```

### 2. æ¨¡å‹è®­ç»ƒ

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¼€å§‹è®­ç»ƒï¼š

```bash
python -m keras_segmentation.train \
    --checkpoints_path="weights/resunet" \
    --train_images="tongue_data/train_img/" \
    --train_annotations="tongue_data/train_label/" \
    --val_images="tongue_data/test_img/" \
    --val_annotations="tongue_data/test_label/" \
    --n_classes=2 \
    --input_height=512 \
    --input_width=512 \
    --model_name="resunet" \
    --batch_size=8 \
    --epochs=50
```

å‚æ•°è¯´æ˜ï¼š
- `--checkpoints_path`: æ¨¡å‹æƒé‡ä¿å­˜è·¯å¾„
- `--train_images`: è®­ç»ƒé›†å›¾åƒè·¯å¾„
- `--train_annotations`: è®­ç»ƒé›†æ ‡æ³¨è·¯å¾„
- `--val_images`: éªŒè¯é›†å›¾åƒè·¯å¾„
- `--val_annotations`: éªŒè¯é›†æ ‡æ³¨è·¯å¾„
- `--n_classes`: åˆ†ç±»æ•°é‡ï¼ˆ2è¡¨ç¤ºäºŒåˆ†ç±»ï¼šèˆŒä½“å’ŒèƒŒæ™¯ï¼‰
- `--input_height/width`: è¾“å…¥å›¾åƒå°ºå¯¸
- `--model_name`: æ¨¡å‹æ¶æ„åç§°
- `--batch_size`: æ‰¹æ¬¡å¤§å°
- `--epochs`: è®­ç»ƒè½®æ•°

### 3. æ¨¡å‹è¯„ä¼°

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼š

```bash
python -m keras_segmentation.predict \
    --checkpoints_path="weights/resunet" \
    --input_path="example/test.jpg" \
    --output_path="example/test_pred.png"
```

åœ¨å®éªŒæŠ¥å‘Šä¸­å¯ä»¥åŒ…å«ä»¥ä¸‹è¯„ä¼°æŒ‡æ ‡ï¼š
- IoU (Intersection over Union)
- F1-Score
- ç²¾ç¡®ç‡å’Œå¬å›ç‡
- åˆ†å‰²å¯è§†åŒ–ç»“æœ

### 4. è‡ªå®šä¹‰è®­ç»ƒè„šæœ¬ï¼ˆå¯é€‰ï¼‰

å¯ä»¥åˆ›å»ºè‡ªå®šä¹‰è®­ç»ƒè„šæœ¬ `train/train.py`ï¼Œä»¥å®ç°æ›´å¤æ‚çš„è®­ç»ƒç­–ç•¥ï¼š

```python
# ç¤ºä¾‹ä»£ç ç‰‡æ®µ
import tensorflow as tf
from keras_segmentation.models.resunet import resunet

# æ•°æ®å¢å¼º
def data_augmentation(image, mask):
    # éšæœºç¿»è½¬
    if tf.random.uniform(()) > 0.5:
        image = tf.image.flip_left_right(image)
        mask = tf.image.flip_left_right(mask)
    
    # éšæœºäº®åº¦è°ƒæ•´
    image = tf.image.random_brightness(image, 0.2)
    
    # éšæœºå¯¹æ¯”åº¦è°ƒæ•´
    image = tf.image.random_contrast(image, 0.8, 1.2)
    
    return image, mask

# è‡ªå®šä¹‰æŸå¤±å‡½æ•°
def dice_loss(y_true, y_pred):
    smooth = 1.
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

# åˆ›å»ºå¹¶ç¼–è¯‘æ¨¡å‹
model = resunet(n_classes=2, input_height=512, input_width=512)
model.compile(optimizer='adam', loss=dice_loss, metrics=['accuracy'])

# è®­ç»ƒæ¨¡å‹
model.fit(train_generator, validation_data=val_generator, epochs=50, callbacks=[...])
```

## é«˜çº§åŠŸèƒ½å’Œæ‰©å±• ğŸš€

### 1. æ‰¹é‡å¤„ç†å’Œåˆ†æ ğŸ“ˆ

åˆ›å»ºæ‰¹å¤„ç†è„šæœ¬ `batch_process.py`ï¼Œèƒ½å¤Ÿå¯¹æ•´ä¸ªæ–‡ä»¶å¤¹ä¸­çš„èˆŒåƒè¿›è¡Œæ‰¹é‡åˆ†æï¼š

```python
import os
import glob
from run import analysis, find_tongue

def batch_process(folder_path, user_id):
    """æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒ"""
    results = []
    image_files = glob.glob(os.path.join(folder_path, "*.jpg")) + \
                  glob.glob(os.path.join(folder_path, "*.png"))
    
    for image_path in image_files:
        print(f"å¤„ç†å›¾åƒ: {os.path.basename(image_path)}")
        det_res = find_tongue(image_path)
        if len(det_res) != 2:
            print(f"èˆŒä½“æ£€æµ‹å¤±è´¥: {det_res}")
            continue
        
        result, mask = det_res
        analysis_result = analysis(image_path, user_id)
        results.append({
            "image": os.path.basename(image_path),
            "result": analysis_result
        })
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    results = batch_process("example/batch_images", "test_user")
    for res in results:
        print(f"å›¾åƒ: {res['image']}, å¥åº·å€¼: {res['result']['res']['healthy']}")
```

### 2. æ—¶é—´åºåˆ—åˆ†æ ğŸ“…

æ·»åŠ ä¸€ä¸ªæ—¶é—´åºåˆ—åˆ†ææ¨¡å—ï¼Œå¯ä»¥æ¯”è¾ƒç”¨æˆ·å¤šæ¬¡æ£€æµ‹ç»“æœçš„å˜åŒ–è¶‹åŠ¿ï¼š

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_health_trend(user_id):
    """åˆ†æç”¨æˆ·å¥åº·è¶‹åŠ¿"""
    excel_path = os.path.join("example", "expert_diagnosis.xlsx")
    if not os.path.exists(excel_path):
        return "æ— å†å²æ•°æ®"
    
    df = pd.read_excel(excel_path)
    user_data = df[df['ç”¨æˆ·ID'] == user_id]
    
    if len(user_data) < 2:
        return "æ•°æ®ç‚¹ä¸è¶³ï¼Œæ— æ³•åˆ†æè¶‹åŠ¿"
    
    # ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾
    plt.figure(figsize=(12, 8))
    plt.subplot(2, 1, 1)
    plt.plot(user_data['æ£€æµ‹æ—¶é—´'], user_data['æ•´ä½“å¥åº·å€¼'], 'o-', label='æ•´ä½“å¥åº·å€¼')
    plt.xlabel('æ£€æµ‹æ—¶é—´')
    plt.ylabel('å¥åº·å€¼')
    plt.title(f'ç”¨æˆ· {user_id} çš„å¥åº·è¶‹åŠ¿')
    plt.grid(True)
    plt.legend()
    
    # ç»˜åˆ¶å„å™¨å®˜å¥åº·å€¼çƒ­åŠ›å›¾
    plt.subplot(2, 1, 2)
    organ_data = user_data[['å¿ƒ', 'è„¾', 'è‚¾', 'è‚º', 'è‚']]
    sns.heatmap(organ_data.T, annot=True, cmap='RdYlGn', 
                xticklabels=user_data['æ£€æµ‹æ—¶é—´'], yticklabels=['å¿ƒ', 'è„¾', 'è‚¾', 'è‚º', 'è‚'])
    plt.title('äº”è„å¥åº·å€¼å˜åŒ–')
    plt.tight_layout()
    
    plt.savefig(f"example/trend_{user_id}.png")
    return f"è¶‹åŠ¿åˆ†æå·²ä¿å­˜è‡³ example/trend_{user_id}.png"
```

### 3. èˆŒè±¡ç‰¹å¾å¯è§†åŒ– ğŸŒˆ

æ·»åŠ ä¸€ä¸ªæ¨¡å—ï¼Œå°†èˆŒä½“çš„ç‰¹å¾è¿›è¡Œå¯è§†åŒ–å±•ç¤ºï¼š

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

def visualize_tongue_features(image_path, mask):
    """èˆŒè±¡ç‰¹å¾å¯è§†åŒ–"""
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # æå–èˆŒä½“åŒºåŸŸ
    tongue_region = cv2.bitwise_and(img, img, mask=mask)
    
    # è®¡ç®—èˆŒä½“é¢œè‰²ç›´æ–¹å›¾
    hsv_tongue = cv2.cvtColor(tongue_region, cv2.COLOR_RGB2HSV)
    h_hist = cv2.calcHist([hsv_tongue], [0], mask, [180], [0, 180])
    s_hist = cv2.calcHist([hsv_tongue], [1], mask, [256], [0, 256])
    v_hist = cv2.calcHist([hsv_tongue], [2], mask, [256], [0, 256])
    
    # ç»˜åˆ¶å¯è§†åŒ–å›¾
    plt.figure(figsize=(15, 10))
    
    # åŸå›¾å’Œåˆ†å‰²ç»“æœ
    plt.subplot(2, 3, 1)
    plt.imshow(img)
    plt.title('åŸå§‹å›¾åƒ')
    plt.axis('off')
    
    plt.subplot(2, 3, 2)
    plt.imshow(tongue_region)
    plt.title('èˆŒä½“åŒºåŸŸ')
    plt.axis('off')
    
    # é¢œè‰²åˆ†å¸ƒç›´æ–¹å›¾
    plt.subplot(2, 3, 3)
    plt.plot(h_hist, color='r', label='Hé€šé“')
    plt.plot(s_hist, color='g', label='Sé€šé“')
    plt.plot(v_hist, color='b', label='Vé€šé“')
    plt.title('é¢œè‰²åˆ†å¸ƒç›´æ–¹å›¾')
    plt.legend()
    
    # èˆŒä½“è¡¨é¢çº¹ç†åˆ†æ
    plt.subplot(2, 3, 4)
    gray_tongue = cv2.cvtColor(tongue_region, cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(gray_tongue, 50, 150)
    plt.imshow(edges, cmap='gray')
    plt.title('èˆŒä½“è¾¹ç¼˜ç‰¹å¾')
    plt.axis('off')
    
    # ä¿å­˜ç»“æœ
    plt.tight_layout()
    plt.savefig(f"example/features_{os.path.basename(image_path)}.png")
    
    return f"ç‰¹å¾å¯è§†åŒ–å·²ä¿å­˜è‡³ example/features_{os.path.basename(image_path)}.png"
```

## å®éªŒåˆ†æä¸è¯„ä¼° ğŸ“

### 1. æ¨¡å‹æ€§èƒ½è¯„ä¼°

å¯¹èˆŒä½“åˆ†å‰²æ¨¡å‹è¿›è¡Œæ€§èƒ½è¯„ä¼°æ˜¯å®éªŒæŠ¥å‘Šçš„é‡è¦éƒ¨åˆ†ã€‚å»ºè®®åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š

- **é‡åŒ–æŒ‡æ ‡**ï¼šè®¡ç®—å¹¶æŠ¥å‘ŠIoUã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1å€¼ç­‰æŒ‡æ ‡
- **å¯è§†åŒ–æ¯”è¾ƒ**ï¼šå¯¹æ¯”åŸå§‹å›¾åƒã€çœŸå®æ ‡ç­¾å’Œæ¨¡å‹é¢„æµ‹ç»“æœ
- **æ¶ˆèå®éªŒ**ï¼šå°è¯•ä¸åŒçš„æ¨¡å‹æ¶æ„æˆ–å‚æ•°è®¾ç½®ï¼Œæ¯”è¾ƒæ€§èƒ½å·®å¼‚
- **æ··æ·†çŸ©é˜µ**ï¼šåˆ†æåˆ†ç±»é”™è¯¯çš„æ¨¡å¼å’ŒåŸå› 

### 2. ä¸´åºŠæœ‰æ•ˆæ€§è¯„ä¼°

ä¸ä¼ ç»Ÿä¸­åŒ»èˆŒè¯Šç»“æœè¿›è¡Œå¯¹æ¯”ï¼Œè¯„ä¼°ç³»ç»Ÿçš„ä¸´åºŠæœ‰æ•ˆæ€§ï¼š

- **ä¸“å®¶å¯¹æ¯”**ï¼šå°†ç³»ç»Ÿè¯Šæ–­ç»“æœä¸ä¸­åŒ»ä¸“å®¶è¯Šæ–­ç»“æœè¿›è¡Œå¯¹æ¯”
- **ä¸€è‡´æ€§åˆ†æ**ï¼šè®¡ç®—ç³»ç»Ÿä¸ä¸“å®¶è¯Šæ–­çš„ä¸€è‡´æ€§æŒ‡æ ‡ï¼ˆå¦‚Kappaç³»æ•°ï¼‰
- **æ¡ˆä¾‹åˆ†æ**ï¼šé€‰æ‹©å…¸å‹æ¡ˆä¾‹è¯¦ç»†åˆ†æç³»ç»Ÿè¯Šæ–­ç»“æœä¸ä¸“å®¶æ„è§çš„å¼‚åŒ
- **å±€é™æ€§è®¨è®º**ï¼šåˆ†æå½“å‰ç³»ç»Ÿçš„å±€é™æ€§å’Œå¯èƒ½çš„æ”¹è¿›æ–¹å‘

### 3. ç³»ç»ŸæŠ€æœ¯äº®ç‚¹

åœ¨å®éªŒæŠ¥å‘Šä¸­é‡ç‚¹å¼ºè°ƒä»¥ä¸‹æŠ€æœ¯äº®ç‚¹ï¼š

- **å¤šä»»åŠ¡å­¦ä¹ **ï¼šåŒæ—¶è¿›è¡ŒèˆŒä½“åˆ†å‰²å’Œå¥åº·çŠ¶æ€è¯„ä¼°
- **é¢†åŸŸçŸ¥è¯†èåˆ**ï¼šå°†ä¼ ç»Ÿä¸­åŒ»ç†è®ºä¸ç°ä»£æœºå™¨å­¦ä¹ æŠ€æœ¯ç»“åˆ
- **ä¸ªæ€§åŒ–åˆ†æ**ï¼šåŸºäºç”¨æˆ·å†å²æ•°æ®è¿›è¡Œä¸ªæ€§åŒ–å¥åº·è¯„ä¼°
- **å¯è§£é‡Šæ€§**ï¼šç³»ç»Ÿä¸ä»…ç»™å‡ºå¥åº·è¯„åˆ†ï¼Œè¿˜æä¾›å…·ä½“çš„è¯Šæ–­å»ºè®®
- **ç«¯åˆ°ç«¯æ–¹æ¡ˆ**ï¼šä»å›¾åƒè¾“å…¥åˆ°å¥åº·è¯„ä¼°çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ

## æ•°æ®é›†åˆ’åˆ†å·¥å…· ğŸ”€

ç³»ç»Ÿè¿˜æä¾›äº†æ•°æ®é›†åˆ’åˆ†å·¥å…· `label/divide_datasets.py`ï¼Œç”¨äºå°†èˆŒåƒæ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š

```bash
python label/divide_datasets.py
```

### æ‰§è¡Œç»“æœï¼š

- å°† `tongue_images/` ç›®å½•ä¸‹çš„å›¾åƒå’Œ `tongue_labels/` ç›®å½•ä¸‹çš„æ ‡ç­¾
- æŒ‰ 9:1 çš„æ¯”ä¾‹éšæœºåˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
- è®­ç»ƒé›†å­˜å‚¨åœ¨ `tongue_data/train_img/` å’Œ `tongue_data/train_label/`
- æµ‹è¯•é›†å­˜å‚¨åœ¨ `tongue_data/test_img/` å’Œ `tongue_data/test_label/`

## æ³¨æ„äº‹é¡¹ âš ï¸

1. èˆŒåƒå›¾ç‰‡éœ€è¦å…‰çº¿é€‚ä¸­ï¼Œæ¸…æ™°å¯è§ï¼Œä¸”èˆŒä½“å æ®å›¾åƒä¸»è¦éƒ¨åˆ†
2. é¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½å’Œé…ç½®æ¨¡å‹æƒé‡
3. è¯Šæ–­ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­
4. ä½¿ç”¨å‰è¯·å¤‡ä»½é‡è¦æ•°æ®ï¼Œå°¤å…¶æ˜¯è¿è¡Œæ•°æ®é›†åˆ’åˆ†å·¥å…·æ—¶
5. æ¨¡å‹è®­ç»ƒéœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºï¼Œå»ºè®®ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹

## å¸¸è§é—®é¢˜è§£ç­” â“

1. **å›¾åƒæ£€æµ‹å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**
   - è¯·ç¡®ä¿å›¾åƒæ¸…æ™°ã€å…‰çº¿é€‚ä¸­ï¼Œä¸”èˆŒä½“å æ®å›¾åƒä¸»è¦éƒ¨åˆ†
   - å°è¯•è°ƒæ•´å›¾åƒçš„äº®åº¦ã€å¯¹æ¯”åº¦æˆ–æ›´æ¢å›¾åƒ

2. **å¦‚ä½•ä¸ºä¸åŒç”¨æˆ·è¿›è¡Œåˆ†æï¼Ÿ**
   - ä¿®æ”¹ `run.py` ä¸­ `analysis()` å‡½æ•°è°ƒç”¨æ—¶çš„ `user_id` å‚æ•°

3. **å¦‚ä½•æŸ¥çœ‹å†å²åˆ†æç»“æœï¼Ÿ**
   - æ‰“å¼€ `example/expert_diagnosis.xlsx` æ–‡ä»¶æŸ¥çœ‹æ‰€æœ‰åˆ†æè®°å½•

4. **å¦‚ä½•é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Ÿ**
   - æŒ‰ç…§"è®­ç»ƒæ¨¡å‹"ç« èŠ‚çš„æ­¥éª¤è¿›è¡Œè®­ç»ƒ

5. **å¦‚ä½•è°ƒæ•´è¯Šæ–­é˜ˆå€¼ï¼Ÿ**
   - åœ¨ `run.py` ä¸­ä¿®æ”¹ç›¸åº”çš„é˜ˆå€¼å‚æ•°ï¼Œå¦‚ `abs(result2['res']['heart']) > 0.4` ä¸­çš„ 0.4

## æœªæ¥å·¥ä½œå±•æœ› ğŸ”®

1. **å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆèˆŒè¯Šã€è„‰è¯Šç­‰å¤šç§ä¸­åŒ»è¯Šæ–­æ–¹æ³•
2. **ç§»åŠ¨ç«¯éƒ¨ç½²**ï¼šå¼€å‘ç§»åŠ¨åº”ç”¨ï¼Œæ–¹ä¾¿ç”¨æˆ·è‡ªä¸»æ£€æµ‹
3. **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒä¸­è‹±ç­‰å¤šç§è¯­è¨€ç•Œé¢
4. **ä¸ªæ€§åŒ–æ¨è**ï¼šåŸºäºè¯Šæ–­ç»“æœæ¨èä¸ªæ€§åŒ–çš„ä¿å¥å»ºè®®
5. **æ•°æ®æŒ–æ˜**ï¼šå¯¹å¤§é‡ç”¨æˆ·æ•°æ®è¿›è¡ŒæŒ–æ˜ï¼Œå‘ç°ç–¾ç—…æ¨¡å¼

## å‚è€ƒæ–‡çŒ® ğŸ“š

1. ç‹å¿ æ°‘. èˆŒè¯Šåœ¨ä¸­åŒ»è¯Šæ–­ä¸­çš„åº”ç”¨ç ”ç©¶[J]. ä¸­åŒ»å­¦æŠ¥, 2018, 33(5): 825-828.
2. Zhang B, Kumar B V, Zhang D. Detecting diabetes mellitus and nonproliferative diabetic retinopathy using tongue color, texture, and geometry features[J]. IEEE Transactions on Biomedical Engineering, 2013, 61(2): 491-501.
3. Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241.
4. ææ¾, å¼ ä¼Ÿ, ç‹å½¤. åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸­åŒ»èˆŒè±¡å®¢è§‚åŒ–ç ”ç©¶è¿›å±•[J]. ä¸­å›½ä¸­åŒ»è¯ä¿¡æ¯æ‚å¿—, 2020, 27(3): 113-117. 